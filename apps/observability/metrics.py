"""
Prometheus metrics: pipeline throughput, publish success/failure, LLM latency, queue depth.
Lightweight: prometheus_client; lazy init.
"""
from typing import TYPE_CHECKING, Optional

try:
    from prometheus_client import Counter, Gauge, Histogram, CollectorRegistry, generate_latest
    HAS_PROMETHEUS = True
except ImportError:
    HAS_PROMETHEUS = False

if TYPE_CHECKING:
    from sqlalchemy.orm import Session

METRICS_REGISTRY: Optional["CollectorRegistry"] = None

# Metrics (lazy init)
pipeline_step_items_total: Optional["Counter"] = None
publish_total: Optional["Counter"] = None
llm_latency_seconds: Optional["Histogram"] = None
items_ingested_total: Optional["Counter"] = None
drafts_generated_total: Optional["Counter"] = None
publications_success_total: Optional["Counter"] = None
publications_failed_total: Optional["Counter"] = None
pipeline_cycle_duration_seconds: Optional["Histogram"] = None
queue_depth: Optional["Gauge"] = None


def _ensure_metrics() -> None:
    global pipeline_step_items_total, publish_total, llm_latency_seconds  # noqa: PLW0603
    global items_ingested_total, drafts_generated_total, publications_success_total
    global publications_failed_total, pipeline_cycle_duration_seconds, queue_depth, METRICS_REGISTRY
    if not HAS_PROMETHEUS:
        return
    if pipeline_step_items_total is not None:
        return
    METRICS_REGISTRY = CollectorRegistry()
    queue_depth = Gauge(
        "queue_depth",
        "Number of items in pipeline by stage (new, scored, drafted)",
        ["stage"],
        registry=METRICS_REGISTRY,
    )
    pipeline_step_items_total = Counter(
        "pipeline_step_items_total",
        "Items processed per pipeline step",
        ["step"],
        registry=METRICS_REGISTRY,
    )
    publish_total = Counter(
        "publish_total",
        "Publications by channel and status",
        ["channel", "status"],
        registry=METRICS_REGISTRY,
    )
    llm_latency_seconds = Histogram(
        "llm_latency_seconds",
        "LLM call latency in seconds",
        ["operation"],
        buckets=(0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0),
        registry=METRICS_REGISTRY,
    )
    items_ingested_total = Counter(
        "items_ingested_total",
        "Total items ingested (RSS + Telegram)",
        registry=METRICS_REGISTRY,
    )
    drafts_generated_total = Counter(
        "drafts_generated_total",
        "Total drafts generated by LLM",
        registry=METRICS_REGISTRY,
    )
    publications_success_total = Counter(
        "publications_success_total",
        "Total successful publications",
        registry=METRICS_REGISTRY,
    )
    publications_failed_total = Counter(
        "publications_failed_total",
        "Total failed publications",
        registry=METRICS_REGISTRY,
    )
    pipeline_cycle_duration_seconds = Histogram(
        "pipeline_cycle_duration_seconds",
        "Pipeline cycle duration in seconds",
        buckets=(1.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0),
        registry=METRICS_REGISTRY,
    )


def update_queue_depth(session: "Session") -> None:
    """Set queue_depth gauge from DB item counts by status. Call before get_metrics() for current values."""
    if not HAS_PROMETHEUS:
        return
    _ensure_metrics()
    try:
        from apps.api.db.models import Item
        from sqlalchemy import func
        for stage in ("new", "scored", "drafted"):
            count = session.query(func.count(Item.id)).filter(Item.status == stage).scalar() or 0
            queue_depth.labels(stage=stage).set(count)
    except Exception:
        pass


def get_metrics() -> bytes:
    """Return Prometheus exposition format. Safe when prometheus_client not installed."""
    if not HAS_PROMETHEUS:
        return b""
    _ensure_metrics()
    reg = METRICS_REGISTRY
    return generate_latest(reg) if reg else b""


def record_pipeline_step(step: str, count: int) -> None:
    """Record items processed in a pipeline step."""
    if not HAS_PROMETHEUS or count <= 0:
        return
    _ensure_metrics()
    pipeline_step_items_total.labels(step=step).inc(count)


def record_publish(channel: str, status: str, count: int = 1) -> None:
    """Record publish success/failure."""
    if not HAS_PROMETHEUS:
        return
    _ensure_metrics()
    publish_total.labels(channel=channel, status=status).inc(count)


def record_llm_latency(operation: str, seconds: float) -> None:
    """Record LLM call latency."""
    if not HAS_PROMETHEUS or seconds < 0:
        return
    _ensure_metrics()
    llm_latency_seconds.labels(operation=operation).observe(seconds)


def record_items_ingested(count: int) -> None:
    """Record items ingested by collector."""
    if not HAS_PROMETHEUS or count <= 0:
        return
    _ensure_metrics()
    items_ingested_total.inc(count)


def record_drafts_generated(count: int) -> None:
    """Record drafts generated by LLM step."""
    if not HAS_PROMETHEUS or count <= 0:
        return
    _ensure_metrics()
    drafts_generated_total.inc(count)


def record_publication_success(count: int = 1) -> None:
    """Record successful publication."""
    if not HAS_PROMETHEUS or count <= 0:
        return
    _ensure_metrics()
    publications_success_total.inc(count)


def record_publication_failure(count: int = 1) -> None:
    """Record failed publication."""
    if not HAS_PROMETHEUS or count <= 0:
        return
    _ensure_metrics()
    publications_failed_total.inc(count)


def record_pipeline_cycle_duration(seconds: float) -> None:
    """Record pipeline cycle duration."""
    if not HAS_PROMETHEUS or seconds < 0:
        return
    _ensure_metrics()
    pipeline_cycle_duration_seconds.observe(seconds)
